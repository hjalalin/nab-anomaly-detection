{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Anomaly Detection on Machine Temperature Data\n",
    "\n",
    "This notebook demonstrates how to build and evaluate an LSTM Autoencoder for anomaly detection using the NAB machine temperature dataset.  \n",
    "We train the model on normal operating data and use reconstruction errors to flag anomalies.  \n",
    "The evaluation covers both point-level detection accuracy and anomaly window–based metrics, reflecting industrial needs for early fault detection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T03:43:28.340591Z",
     "iopub.status.busy": "2025-08-05T03:43:28.340373Z",
     "iopub.status.idle": "2025-08-05T03:43:37.233450Z",
     "shell.execute_reply": "2025-08-05T03:43:37.232496Z",
     "shell.execute_reply.started": "2025-08-05T03:43:28.340572Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "repo_root = pathlib.Path.cwd().resolve().parents[1]  \n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "# utils from this repo\n",
    "from configs.config import DEFAULTS\n",
    "from utils.data_loader import load_dataset\n",
    "from utils.detectors_dl import train_autoencoder, ae_scores, windows_to_pointwise_last\n",
    "from utils.visualizations import plot_methods_subplots, shade_windows\n",
    "from utils.evaluation import evaluate_predictions\n",
    "\n",
    "def adapt_config(defaults):\n",
    "    cfg = {\"stats_global\":{}, \"stats_local\":{}, \"stats_sequential\":{}, \"stats_trend\":{}}\n",
    "    for section, sub in defaults.items():\n",
    "        if section not in cfg:\n",
    "            continue\n",
    "        for key, opts in sub.items():\n",
    "            if isinstance(opts, dict) and \"enabled\" in opts:\n",
    "                if opts[\"enabled\"]:\n",
    "                    cfg[section][key] = {k:v for k,v in opts.items() if k != \"enabled\"}\n",
    "    return cfg\n",
    "\n",
    "config = adapt_config(DEFAULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T03:43:37.395180Z",
     "iopub.status.busy": "2025-08-05T03:43:37.394893Z",
     "iopub.status.idle": "2025-08-05T03:43:37.406926Z",
     "shell.execute_reply": "2025-08-05T03:43:37.405958Z",
     "shell.execute_reply.started": "2025-08-05T03:43:37.395150Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs, merged, windows = load_dataset(\"machine_temperature\")\n",
    "df = dfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Read hyperparameters from your utils.config.DEFAULTS_machine_temperature. \n",
    "Tune sequence length, model size, epochs, and threshold quantile if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull DL + threshold params from your config defaults\n",
    "cfg = DEFAULTS\n",
    "\n",
    "SEQ_LEN = cfg[\"dl\"][\"autoencoder\"][\"seq_len\"]\n",
    "BATCH = cfg[\"dl\"][\"autoencoder\"][\"batch_size\"]\n",
    "EPOCHS = cfg[\"dl\"][\"autoencoder\"][\"epochs\"]\n",
    "HID = cfg[\"dl\"][\"autoencoder\"][\"hidden\"]\n",
    "LAYERS = cfg[\"dl\"][\"autoencoder\"][\"layers\"]\n",
    "DROP = cfg[\"dl\"][\"autoencoder\"][\"dropout\"]\n",
    "DECAY = cfg[\"dl\"][\"autoencoder\"][\"weight_decay\"]\n",
    "LR = cfg[\"dl\"][\"autoencoder\"][\"lr\"]\n",
    "EPOCHS = cfg[\"dl\"][\"autoencoder\"][\"epochs\"]\n",
    "PATIENCE = cfg[\"dl\"][\"autoencoder\"][\"patience\"]\n",
    "\n",
    "\n",
    "print(f\"seq_len={SEQ_LEN}, batch={BATCH}, epochs={EPOCHS}, hidden={HID}, layers={LAYERS},\\\n",
    "       dropout={DROP}, DCCAY={DECAY}, lr={LR}, epochs={EPOCHS}, patience={PATIENCE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "The model is trained only on normal segments (outside failure windows). This ensures the autoencoder is trained solely on normal, healthy behavior, preventing it from learning patterns associated with failures and preserving the model’s ability to generalize to unseen anomalies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_any_failure_window(ts, windows):\n",
    "    for s, e in windows:\n",
    "        if s <= ts <= e:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Mark timestamps inside windows\n",
    "df[\"in_window\"] = df[\"timestamp\"].apply(lambda t: in_any_failure_window(t, windows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by time (70/15/15) to simulate realistic streaming\n",
    "n = len(df)\n",
    "t1 = int(0.7 * n)\n",
    "t2 = int(0.85 * n)\n",
    "\n",
    "train_df = df.iloc[:t1].copy()\n",
    "val_df   = df.iloc[t1:t2].copy()\n",
    "test_df  = df.iloc[t2:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df[\"in_window\"].sum())\n",
    "print(val_df[\"in_window\"].sum())\n",
    "print(test_df[\"in_window\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "failure window in all 3 splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(train_df['timestamp']), max(train_df['timestamp']))\n",
    "print(min(val_df['timestamp']), max(val_df['timestamp']))\n",
    "print(min(test_df['timestamp']), max(test_df['timestamp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sequences(df, seq_len, value_col, use_only_normal=True):\n",
    "    x = df[value_col].to_numpy(dtype=np.float32)\n",
    "    ts = df[\"timestamp\"].to_numpy()\n",
    "    inw = df[\"in_window\"].to_numpy(dtype=bool)\n",
    "\n",
    "    seqs = []\n",
    "    idxs = []\n",
    "    for i in range(len(df) - seq_len + 1):\n",
    "        seg_inw = inw[i:i+seq_len]\n",
    "        if use_only_normal and seg_inw.any():\n",
    "            continue\n",
    "        seq = x[i:i+seq_len].copy()\n",
    "        seqs.append(seq[:, None])  # shape (seq_len, 1)\n",
    "        idxs.append(i + seq_len - 1)  # align to last timestamp for scoring\n",
    "    return np.stack(seqs) if len(seqs)>0 else np.empty((0, seq_len, 1), dtype=np.float32), np.array(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, tr_idx = make_sequences(train_df, SEQ_LEN, value_col ='machine_temperature_system_failure', use_only_normal=True)\n",
    "Xva, va_idx = make_sequences(val_df,   SEQ_LEN, value_col ='machine_temperature_system_failure', use_only_normal=True)\n",
    "Xte, te_idx = make_sequences(test_df,  SEQ_LEN, value_col ='machine_temperature_system_failure', use_only_normal=False)\n",
    "\n",
    "print(\"Train seqs:\", Xtr.shape, \"Val seqs:\", Xva.shape, \"Test seqs:\", Xte.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization\n",
    "To avoid data leakage, the scaler is fit only on the clean training data. The same scaler is then applied to both training and test sets to maintain consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize using training stats\n",
    "mu = Xtr.mean()\n",
    "sd = Xtr.std() if Xtr.std() > 0 else 1.0\n",
    "Xtr_n = (Xtr - mu)/sd\n",
    "Xva_n = (Xva - mu)/sd\n",
    "Xte_n = (Xte - mu)/sd\n",
    "mu, sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1\n",
    "model, history = train_autoencoder(Xtr_n, Xva_n, n_features, cfg[\"dl\"][\"autoencoder\"], verbose=True)\n",
    "\n",
    "# Optional: quick look at losses\n",
    "print(\"Last train loss:\", history[\"train_loss\"][-1] if history[\"train_loss\"] else None)\n",
    "print(\"Last val   loss:\", history[\"val_loss\"][-1] if history[\"val_loss\"] else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly dection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Choose a reduction \n",
    "REDUCE = \"last_t\"  # or 'time_feature_mean' / 'time_feature_max' / 'time_feature_q\n",
    "\n",
    "# 2) Score validation windows and pick a high-quantile threshold \n",
    "val_scores = ae_scores(model, Xva_n, cfg, reduce=REDUCE)   \n",
    "thr = torch.quantile(val_scores, 0.995).item()  \n",
    "\n",
    "# 3) Score test windows\n",
    "test_scores = ae_scores(model, Xte_n, cfg, reduce=REDUCE) \n",
    "\n",
    "# 4) Map window scores to the original timeline (assign to last index of each window)\n",
    "point_scores = windows_to_pointwise_last(test_scores, SEQ_LEN, total_len=len(df), offset=t2)\n",
    "\n",
    "# 5) Threshold → boolean anomaly series\n",
    "point_mask = (point_scores > thr).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores = ae_scores(model, dl_val, cfg, reduce=\"last_t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict_batched(model, Xte_n, cfg, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.mean(dim=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_temp = np.full(len(test_df), np.nan, dtype=float)\n",
    "pred_temp[SEQ_LEN-1:] = preds.mean(axis=(1,2)).numpy() * sd + mu\n",
    "test_df['preds']= pred_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.figure(figsize=(14,3))\n",
    "ax.plot(test_df['timestamp'], test_df['machine_temperature_system_failure'], label='Temperature')\n",
    "ax.plot(test_df['timestamp'], test_df['preds'], label='Predicted Temperature')\n",
    "shade_windows(ax, windows, color=\"red\", alpha=0.25, first_label=\"Failure Time\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "X_train_pred = reconstruct(model, Xtr_n, device=cfg['dl'][\"autoencoder\"][\"device\"])\n",
    "train_err = reconstruction_error(Xtr, X_train_pred, reduce=\"time_feature_mean\")\n",
    "\n",
    "# Validation\n",
    "X_val_pred = reconstruct(model, Xva_n,  device=cfg['dl'][\"autoencoder\"][\"device\"])\n",
    "val_err = reconstruction_error(Xva_n, X_val_pred, reduce=\"time_feature_mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.quantile(list(val_err)+list(test_err), 0.9)\n",
    "mask_val  = (val_err  > threshold)\n",
    "mask_test = (test_err > threshold)\n",
    "\n",
    "print(threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.index>t1]) - len(va_idx)- len(te_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_err)\n",
    "print(len(train_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(len(df), dtype=bool)\n",
    "for i, err in enumerate(val_err):\n",
    "    if err> threshold:\n",
    "        mask[va_idx[i] + len(tr_idx)] = True\n",
    "    else:\n",
    "        mask[va_idx[i] + len(tr_idx)] = False\n",
    "        \n",
    "for i, err in enumerate(test_err):\n",
    "    if err> threshold:\n",
    "        mask[te_idx[i] + len(tr_idx) + len(va_idx)] = True\n",
    "    else:\n",
    "        mask[te_idx[i] + len(tr_idx) + len(va_idx)] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_preds = {'LSTM Autoencoder': mask}\n",
    "\n",
    "plot_methods_subplots(df, methods_preds, value_col=\"machine_temperature_system_failure\", windows=windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_df = df[df.index>t1]\n",
    "val_test_pred = methods_preds['LSTM Autoencoder'][len(tr_idx):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = {'LSTM Autoencoder': evaluate_predictions(val_test_df, val_test_pred , windows, early_tolerance=\"5h\")}\n",
    "        \n",
    "print(pd.DataFrame(eval_results).T.round(3))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
